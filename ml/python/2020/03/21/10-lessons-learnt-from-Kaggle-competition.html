<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Lesson learnt from Kaggle - Bengali Image Classification Competition | mediumnokâœŠ</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Lesson learnt from Kaggle - Bengali Image Classification Competition" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lesson learnt from kaggle competition" />
<meta property="og:description" content="Lesson learnt from kaggle competition" />
<link rel="canonical" href="https://noklam.github.io/blog/ml/python/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html" />
<meta property="og:url" content="https://noklam.github.io/blog/ml/python/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html" />
<meta property="og:site_name" content="mediumnokâœŠ" />
<meta property="og:image" content="https://noklam.github.io/blog/images/bengali_00_header.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-21T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://noklam.github.io/blog/ml/python/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html","@type":"BlogPosting","headline":"Lesson learnt from Kaggle - Bengali Image Classification Competition","dateModified":"2020-03-21T00:00:00-05:00","datePublished":"2020-03-21T00:00:00-05:00","image":"https://noklam.github.io/blog/images/bengali_00_header.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://noklam.github.io/blog/ml/python/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html"},"description":"Lesson learnt from kaggle competition","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://noklam.github.io/blog/feed.xml" title="mediumnokâœŠ" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-83544344-5','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">mediumnokâœŠ</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/fsdl/">Full Stack Deep Learning</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Lesson learnt from Kaggle - Bengali Image Classification Competition</h1><p class="page-description">Lesson learnt from kaggle competition</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-21T00:00:00-05:00" itemprop="datePublished">
        Mar 21, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="blog/categories/#ML">ML</a>
        &nbsp;
      
        <a class="category-tags-link" href="blog/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/noklam/blog/tree/master/_notebooks/2020-03-21-10-lessons-learnt-from-Kaggle-competition.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/noklam/blog/master?filepath=_notebooks%2F2020-03-21-10-lessons-learnt-from-Kaggle-competition.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/noklam/blog/blob/master/_notebooks/2020-03-21-10-lessons-learnt-from-Kaggle-competition.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#The-Classification-Task">The Classification Task </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Evaluation-Metrics">Evaluation Metrics </a></li>
<li class="toc-entry toc-h2"><a href="#Model-(Bigger-still-better)">Model (Bigger still better) </a></li>
<li class="toc-entry toc-h2"><a href="#Augmentation">Augmentation </a>
<ul>
<li class="toc-entry toc-h3"><a href="#CutMix-&-MixUp">CutMix &amp; MixUp </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Logging-of-Experiment">Logging of Experiment </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Hydra">Hydra </a></li>
<li class="toc-entry toc-h2"><a href="#Wandb">Wandb </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Stochastic-Weight-Averaging">Stochastic Weight Averaging </a></li>
<li class="toc-entry toc-h1"><a href="#"></a></li>
<li class="toc-entry toc-h1"><a href="#Larger-is-better-(image-size)">Larger is better (image size) </a></li>
<li class="toc-entry toc-h1"><a href="#Debug-&-Checkpoint">Debug &amp; Checkpoint </a></li>
<li class="toc-entry toc-h1"><a href="#Use-auxiliary-label">Use auxiliary label </a></li>
<li class="toc-entry toc-h1"><a href="#Weight-loss">Weight loss </a></li>
<li class="toc-entry toc-h1"><a href="#Find-a-teammate!">Find a teammate! </a></li>
<li class="toc-entry toc-h1"><a href="#Pretrain-Model">Pretrain Model </a></li>
<li class="toc-entry toc-h1"><a href="#If-the-code-works,-don't-touch-it">If the code works, don&#39;t touch it </a></li>
<li class="toc-entry toc-h1"><a href="#Summary">Summary </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-21-10-lessons-learnt-from-Kaggle-competition.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I have teamed up with a friend to participate in the <a href="https://www.kaggle.com/c/bengaliai-cv19/?utm_medium=email&amp;utm_source=intercom&amp;utm_campaign=bengaliai-email-launch">Bengali Image Classification Competition</a>. We struggled to get a high rank in the Public leaderboard throughout the competition.  In the end, the result is a big surprise to everyone as the leaderboard shook a lot.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_0_public_lb.png?raw=true" alt="Public Leaderboard" title="Public Leaderboard has a much higher score, &gt;0.99 recall!"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_1_private_lb.png?raw=true" alt="Public Leaderboard" title="Note that the rank shook for over 1000!"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The final private score was much lower than the public score. It suggests that most participants are over-fitting Public leaderboard.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-Classification-Task">
<a class="anchor" href="#The-Classification-Task" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Classification Task<a class="anchor-link" href="#The-Classification-Task"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is an image classification competition. We need to predict 3 parts of <strong>Bengali</strong> characters <code>root</code>, <code>consonant</code> and <code>vowel</code>. It is a typical classification tasks like the <strong>MNIST</strong> dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_2_grapheme.png?raw=true" alt="Grapheme example" title="Examples of characters"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-Metrics">
<a class="anchor" href="#Evaluation-Metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluation Metrics<a class="anchor-link" href="#Evaluation-Metrics"> </a>
</h2>
<p>The competition use macro-recall as the evaluation metric. In general, people get &gt;96% recall in training, the tops are even getting &gt;99% recall.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># collapse-hide</span>
<span class="n">python</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span>

<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'grapheme_root'</span><span class="p">,</span> <span class="s1">'consonant_diacritic'</span><span class="p">,</span> <span class="s1">'vowel_diacritic'</span><span class="p">]:</span>
    <span class="n">y_true_subset</span> <span class="o">=</span> <span class="n">solution</span><span class="p">[</span><span class="n">solution</span><span class="p">[</span><span class="n">component</span><span class="p">]</span> <span class="o">==</span> <span class="n">component</span><span class="p">][</span><span class="s1">'target'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">y_pred_subset</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="n">submission</span><span class="p">[</span><span class="n">component</span><span class="p">]</span> <span class="o">==</span> <span class="n">component</span><span class="p">][</span><span class="s1">'target'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span>
        <span class="n">y_true_subset</span><span class="p">,</span> <span class="n">y_pred_subset</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">'macro'</span><span class="p">))</span>
<span class="n">final_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-(Bigger-still-better)">
<a class="anchor" href="#Model-(Bigger-still-better)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model (Bigger still better)<a class="anchor-link" href="#Model-(Bigger-still-better)"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We start with <code>xresnet50</code>, which is a relatively small model. As we have the assumption that this classification task is a very standard task, therefore the difference of model will not be the most important one. Thus we pick xresnet50 as it has a good performance in terms of accuracy and train relatively fast.</p>
<p>Near the end of the competition, we switch to a larger model <code>se-resnext101</code>. It requires triple training time plus we have to scale down the batch size as it does not fit into the GPU memory. Surprisingly (maybe not surprising to everyone), the bigger model did boost the performance more than I expected with ~0.3-0.5% recall. It is a big improvement as the recall is very high (~0.97), in other words, it reduces <strong>~10%</strong>  error solely by just using a better model, not bad!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Augmentation">
<a class="anchor" href="#Augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Augmentation<a class="anchor-link" href="#Augmentation"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are never "enough" data for deep learning, so we always try our best to collect more data. Since we cannot collect more data, we need data augmentation.
We start with rotation + scale. We also find <strong>MixUp</strong> and <strong>CutMix</strong> is very effective to boost the performance. It also gives us roughly <strong>10%</strong> boost initially from 0.96 -&gt; 0.964 recall.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CutMix-&amp;-MixUp">
<a class="anchor" href="#CutMix-&amp;-MixUp" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://arxiv.org/abs/1905.04899">CutMix</a> &amp; <a href="https://arxiv.org/pdf/1710.09412.pdf">MixUp</a><a class="anchor-link" href="#CutMix-&amp;-MixUp"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_3_data_aug.png?raw=true" alt="Example of Augmentation" title="Augmentation Example"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>Mixup</em> is simple, if you know about photography, it is similar to have double exposure of your photos. It overlays two images (cat+dog in this case) by sampling weights. So instead of prediction P(dog) = 1, the new target could become P(dog) = 0.8 and P(cat) = 0.2.</p>
<p><em>CutMix</em> shares a similar idea, instead of overlay 2 images, it crops out a certain ratio of the image and replaces it with another one.</p>
<p>It always surprises me that these augmented data does not make much sense to a human, but it is very effective to improve model accuracy and reduce overfitting empirically.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Logging-of-Experiment">
<a class="anchor" href="#Logging-of-Experiment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logging of Experiment<a class="anchor-link" href="#Logging-of-Experiment"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I normally just log my experiment with a simple CSV and some printing message. This start to get tedious when there are more than 1 people to work. It is important to communicate the results of experiments. I explore <code>Hydra</code> and <code>wandb</code> in this competition and they are very useful.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hydra">
<a class="anchor" href="#Hydra" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://hydra.cc/">Hydra</a><a class="anchor-link" href="#Hydra"> </a>
</h2>
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_4_hydra.png?raw=true" alt="Hydra for configuration composition"></p>
<p>It is often a good idea to make your experiment configurable. We use <code>Hydra</code> for this purpose and it is useful to compose different configuration group.
By making your hyper-paramters configurable, you can define an experiment by configuration files and run multiple experiments. By logging the configuration with the training statistics, it is easy to do cross-models comparison and find out which configuration is useful for your model.</p>
<p>I have written <a href="https://mediumnok.ml/coding/ml/2020/02/08/Config-Composition-with-Hydra-for-Machine-Learning-Experiments.html">an short example</a> for how to use <strong>Hydra</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wandb">
<a class="anchor" href="#Wandb" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://www.wandb.com/">Wandb</a><a class="anchor-link" href="#Wandb"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>wandb</strong> (Weight &amp; Biases) does a few things. It provides built-in functions that automatically  log all your model statistics, you can also log your custom metrics with simple functions.</p>
<ul>
<li>Compare the configuration of different experiments to find out the model with the best performance.</li>
<li>Built-in function for logging model weights and gradient for debugging purpose.</li>
<li>Log any metrics that you want</li>
</ul>
<p>All of these combined to make collaboration experience better. It is really important to sync the progress frequently and getting everyone results in a single platform makes these conversations easier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_06.jpg?raw=true" alt="image.png" title="Screenshot of wandb UI for cross model comparison"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Stochastic-Weight-Averaging">
<a class="anchor" href="#Stochastic-Weight-Averaging" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/">Stochastic Weight Averaging</a><a class="anchor-link" href="#Stochastic-Weight-Averaging"> </a>
</h1>
<p>This is a simple yet effective technique which gives about 0.3-0.4% boost to my model. In simple words, it takes <strong>snapshots</strong> of the model weights during training and takes an average at the end. It provides a cheap way to do models ensemble while you are only training 1 model. This is important for this competition as it allows me to keep training time short enough to allow feedback within hours and reduce over-fitting.)</p>
<h1>
<a class="anchor" href="#" aria-hidden="true"><span class="octicon octicon-link"></span></a><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_5_swa.png?raw=true" alt="image.png" title="Stochastic Weight Averaging">
</h1>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Larger-is-better-(image-size)">
<a class="anchor" href="#Larger-is-better-(image-size)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Larger is better (image size)<a class="anchor-link" href="#Larger-is-better-(image-size)"> </a>
</h1>
<p>We downsample our image size to 128x128 throughout the competition, as it makes the model train faster and we believe most technique should be transferable to larger image size. It is important to keep your feedback loop short enough (hours if not days). You want your training data as small as possible while keeping them transferable to your full dataset. Once we scale our image to full size, it takes almost 20 hours to train a single model, and we only have little chance to tune the hyper-parameters before the competition end.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Debug-&amp;-Checkpoint">
<a class="anchor" href="#Debug-&amp;-Checkpoint" aria-hidden="true"><span class="octicon octicon-link"></span></a>Debug &amp; Checkpoint<a class="anchor-link" href="#Debug-&amp;-Checkpoint"> </a>
</h1>
<p>There was a time we develop our model separately and we didn't sync our code for a while. We refactor our code during the time and it was a huge mistake. It turns out our pre-refactor code trains much better model and we introduce some unknown bug. It is almost impossible to find out as we change multiple things. It is so hard to debug a neural network and testing it thoroughly  is important. Injecting a large amount of code may help you to run an experiment earlier, but you may pay much more time to debug it afterwards.</p>
<p>I think this is applicable even if you are working alone.</p>
<ul>
<li>Keep your changes small.</li>
<li>Establish a baseline early, always do a regression test after a new feature introduced (especially after code refactoring)</li>
<li>Create checkpoint to rollback anytime, especially if you are not working on it every day.</li>
</ul>
<p>Implementation is the key of Kaggle competition (in real life too). It does not matter how great your model is, a tiny little bug could have damaged your model silently</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Use-auxiliary-label">
<a class="anchor" href="#Use-auxiliary-label" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use auxiliary label<a class="anchor-link" href="#Use-auxiliary-label"> </a>
</h1>
<p><img src="https://github.com/noklam/mediumnok/blob/master/_notebooks/nb_img/bengali_7.png?raw=true" alt="image.png" title="The extra grapheme label">
As mentioned earlier, this competition requires to predict the <code>root</code>, <code>vowel</code> and the <code>consonant</code> part. In the training data, they actually provide the <code>grapheme</code> too. Lots of people saying that if you train with the <code>grapheme</code>, it improves the model greatly and get the recall &gt;98% easily.</p>
<p>This is something we could not reproduce throughout the competition, we tried it in the very last minute but it does not seem to improve our model. It turns out lots of people are overfitting the data, as the testing dataset has much more unseen character.</p>
<p>But it is still a great remark that training with labels that is not your final desired output could still be very useful.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Weight-loss">
<a class="anchor" href="#Weight-loss" aria-hidden="true"><span class="octicon octicon-link"></span></a>Weight loss<a class="anchor-link" href="#Weight-loss"> </a>
</h1>
<p>The distribution of the training dataset is very imbalance, but to get a good result, we need to predict every single class accurately (macro recall). To deal with this issue, we choose to use class weights, where a higher weight would be applied to rare samples. We don't have an ablation study for this, but it seems to help close the gap between accuracy &amp; recall and allows us to train the model slightly better.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Find-a-teammate!">
<a class="anchor" href="#Find-a-teammate!" aria-hidden="true"><span class="octicon octicon-link"></span></a>Find a teammate!<a class="anchor-link" href="#Find-a-teammate!"> </a>
</h1>
<p>Lastly, please go and find a teammate if you can. It is very common to start a Kaggle competition, but not so easy to finish them. I have stopped for a month during the competition due to my job. It is really hard to get back to the competition after you stopped for so long. Getting a teammate helps to motivate you and in the end, it is a great learning experience for both of us.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Pretrain-Model">
<a class="anchor" href="#Pretrain-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pretrain Model<a class="anchor-link" href="#Pretrain-Model"> </a>
</h1>
<p>We also tried to use a pretrained model, as it allows shorter training and gives better performance by transfer learning (Using weights learn from a large dataset to as initial weight). It also gives our model a bit of improvement.</p>
<ul>
<li>Finetune the model head, while keeping other layers freeze (except BatchNorm layer).</li>
<li>Unfreeze the model, train all the layers together.</li>
</ul>
<p>I also tried training the model directly with discriminating learning rate while not freezing any layer at all. It performs similarly  to freezing fine-tuning , so I end up just start training the entire model from the beginning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="If-the-code-works,-don't-touch-it">
<a class="anchor" href="#If-the-code-works,-don't-touch-it" aria-hidden="true"><span class="octicon octicon-link"></span></a>If the code works, don't touch it<a class="anchor-link" href="#If-the-code-works,-don't-touch-it"> </a>
</h1>
<p>This is probably not a good habit usually, but I suggest not to do it for a competition. We spent lots of time for debugging our code after code refactoring and end up just rolling back to an older commit and cherry-picks new features. In a competition, you don't have enough time to test everything. You do not need a nice abstract class for all your features, some refactoring to keep your function/class clean is probably needed, but do not overspend your time on it. It is even common to jump between frameworks (you may find other's Kernel useful), so it is not possible to structure your code perfectly.</p>
<ul>
<li>If someone has create a working submission script, use it!</li>
<li>If someone has create a working pre-processing function, use it!</li>
</ul>
<p>Don't spend time on trying to optimize these code unless it is necessary, it is often not worth it in a competition context. You should focus on adding new features, trying out new model, testing with new augmentation technique instead.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Summary">
<a class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary<a class="anchor-link" href="#Summary"> </a>
</h1>
<p>This is a great learning experience and refreshes  some of my outdated computer vision model knowledge. If you have never joined a competition, find a friend and get started. If you have just finished one, try writing it out and share your experience. ðŸ˜‰</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="noklam/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/ml/python/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Explaining ideas one post at a time. Data Science/Machine Learning/Software Engineering</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/noklam" title="noklam"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/noklamchan" title="noklamchan"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/mediumnok" title="mediumnok"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
