{
  
    
        "post0": {
            "title": "Hey Data Scientist, I can't read your chart",
            "content": "#collapse def make_scatter_plot(): num_points = 100 gradient = 0.5 x = np.array(range(num_points)) y = np.random.randn(num_points) * 10 + x * gradient fig, ax = plt.subplots() ax.scatter(x, y) ax.set_title(&#39;A Simple Scatter Plot&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) plt.show() def make_line_plot(): num_points = 100 gradient = 0.5 x = np.array(range(num_points)) y = np.random.randn(num_points) * 10 + x * gradient fig, ax = plt.subplots() ax.plot(x, y, &#39;-&#39;) ax.set_title(&#39;A Simple Line Chart&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) plt.show() . . The Problem of library defaults . make_scatter_plot() make_line_plot() . Your insight is as best as your audience understand. Data Scientist spends a lot of time to drill insight from data, but not enough time to present their insight. Unfortunately, human perception is largely based on visual, a easy-to-read chart is much more likely to sell your idea with a custom matplotlib pyplot chart. There is nothing wrong with matplotlib, it is custom for a user sit in front of a monitor. When it comes to presentation, you really should make some adjustment for your audience. Luckily, it is easy to do with the following tips. . Apply matplotlib theme . with plt.style.context(&#39;ggplot&#39;): # Or plt.style.use(&#39;presentation&#39;) for global setting make_scatter_plot() make_line_plot() . Much better right? . There is nothing wrong with the chart if you are viewing it in front of your monitor. However, you may not want to put it directly into your PowerPoint. . Make PowerPoint-ready charts . Luckily, there is some easy way to prepare PowerPoint-ready charts. I created a presentation.mplstyle file as follow. . Custom presentation theme . axes.titlesize : 24 axes.labelsize : 24 axes.location: &#39;left&#39; lines.linewidth : 3 lines.markersize : 10 xtick.labelsize : 18 ytick.labelsize : 18 figure.figsize : 10, 6 figure.titlesize: 24 . with plt.style.context([&#39;presentation&#39;, &#39;ggplot&#39;]): make_scatter_plot() make_line_plot() . If you are careful enough, you will notice the font size of the title is not correct. This is because ggplot theme overwrite my theme. To make it right, you just need to switch the order so that your theme will overwrite conflict settings. . with plt.style.context([&#39;ggplot&#39;, &#39;presentation&#39;]): make_scatter_plot() make_line_plot() . I actually disable the grid in my presentation theme, which conflicts with fivethirtyeight configuration. If conflict configs exist, it resolved base on your order. See the same plot with &#39;presentation&#39;,&#39;fivethirtyeight&#39; in reverse order. . To give you a sense how this affect your presenation, I put it into a Powerpoint, see if you feel the difference. . . . Avoid Low Resolution Chart . . Note: Believe it or not, a low resolution chart looks much less conviencing. Taking screenshot with larger charts helps you to preserve the resolution. . Resolution of the chart is much better | More obvious Title &amp; Label (Try take a few step back from your monitor, see if you can read it) | . Define Once, Use Everywhere . It could be troublesome if you need to define the same file over and over in different computer/environment. You can actually use a URL. I have put my own theme in GitHub so I can always access it from anywhere. . https://raw.githubusercontent.com/noklam/mediumnok/master/_demo/python-viz/presentation.mplstyle . my_style = &#39;https://raw.githubusercontent.com/noklam/mediumnok/master/_demo/python-viz/presentation.mplstyle&#39; with plt.style.context([&#39;ggplot&#39;, my_style]): make_scatter_plot() make_line_plot() . Bad key &#34;font.name&#34; on line 9 in https://raw.githubusercontent.com/noklam/mediumnok/master/_demo/python-viz/presentation.mplstyle. You probably need to get an updated matplotlibrc file from https://github.com/matplotlib/matplotlib/blob/v3.2.1/matplotlibrc.template or from the matplotlib source distribution . Conclusion . I hope this blog helps you to prepare Powerpoint-ready charts better, happy coding! .",
            "url": "https://mediumnok.ml/visualization/2020/04/10/Presentation-Ready-Chart.html",
            "relUrl": "/visualization/2020/04/10/Presentation-Ready-Chart.html",
            "date": " ‚Ä¢ Apr 10, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Lesson learnt from Kaggle - Bengali Image Classification Competition",
            "content": "I have teamed up with a friend to participate in the Bengali Image Classification Competition. We struggled to get a high rank in the Public leaderboard throughout the competition. In the end, the result is a big surprise to everyone as the leaderboard shook a lot. . . . The final private score was much lower than the public score. It suggests that most participants are over-fitting Public leaderboard. . The Classification Task . This is an image classification competition. We need to predict 3 parts of Bengali characters root, consonant and vowel. It is a typical classification tasks like the MNIST dataset. . . Evaluation Metrics . The competition use macro-recall as the evaluation metric. In general, people get &gt;96% recall in training, the tops are even getting &gt;99% recall. . # collapse-hide python import numpy as np import sklearn.metrics scores = [] for component in [&#39;grapheme_root&#39;, &#39;consonant_diacritic&#39;, &#39;vowel_diacritic&#39;]: y_true_subset = solution[solution[component] == component][&#39;target&#39;].values y_pred_subset = submission[submission[component] == component][&#39;target&#39;].values scores.append(sklearn.metrics.recall_score( y_true_subset, y_pred_subset, average=&#39;macro&#39;)) final_score = np.average(scores, weights=[2,1,1]) . . Model (Bigger still better) . We start with xresnet50, which is a relatively small model. As we have the assumption that this classification task is a very standard task, therefore the difference of model will not be the most important one. Thus we pick xresnet50 as it has a good performance in terms of accuracy and train relatively fast. . Near the end of the competition, we switch to a larger model se-resnext101. It requires triple training time plus we have to scale down the batch size as it does not fit into the GPU memory. Surprisingly (maybe not surprising to everyone), the bigger model did boost the performance more than I expected with ~0.3-0.5% recall. It is a big improvement as the recall is very high (~0.97), in other words, it reduces ~10% error solely by just using a better model, not bad! . Augmentation . There are never &quot;enough&quot; data for deep learning, so we always try our best to collect more data. Since we cannot collect more data, we need data augmentation. We start with rotation + scale. We also find MixUp and CutMix is very effective to boost the performance. It also gives us roughly 10% boost initially from 0.96 -&gt; 0.964 recall. . CutMix &amp; MixUp . . Mixup is simple, if you know about photography, it is similar to have double exposure of your photos. It overlays two images (cat+dog in this case) by sampling weights. So instead of prediction P(dog) = 1, the new target could become P(dog) = 0.8 and P(cat) = 0.2. . CutMix shares a similar idea, instead of overlay 2 images, it crops out a certain ratio of the image and replaces it with another one. . It always surprises me that these augmented data does not make much sense to a human, but it is very effective to improve model accuracy and reduce overfitting empirically. . Logging of Experiment . I normally just log my experiment with a simple CSV and some printing message. This start to get tedious when there are more than 1 people to work. It is important to communicate the results of experiments. I explore Hydra and wandb in this competition and they are very useful. . Hydra . It is often a good idea to make your experiment configurable. We use Hydra for this purpose and it is useful to compose different configuration group. By making your hyper-paramters configurable, you can define an experiment by configuration files and run multiple experiments. By logging the configuration with the training statistics, it is easy to do cross-models comparison and find out which configuration is useful for your model. . I have written an short example for how to use Hydra. . Wandb . wandb (Weight &amp; Biases) does a few things. It provides built-in functions that automatically log all your model statistics, you can also log your custom metrics with simple functions. . Compare the configuration of different experiments to find out the model with the best performance. | Built-in function for logging model weights and gradient for debugging purpose. | Log any metrics that you want | . All of these combined to make collaboration experience better. It is really important to sync the progress frequently and getting everyone results in a single platform makes these conversations easier. . . Stochastic Weight Averaging . This is a simple yet effective technique which gives about 0.3-0.4% boost to my model. In simple words, it takes snapshots of the model weights during training and takes an average at the end. It provides a cheap way to do models ensemble while you are only training 1 model. This is important for this competition as it allows me to keep training time short enough to allow feedback within hours and reduce over-fitting.) . . Larger is better (image size) . We downsample our image size to 128x128 throughout the competition, as it makes the model train faster and we believe most technique should be transferable to larger image size. It is important to keep your feedback loop short enough (hours if not days). You want your training data as small as possible while keeping them transferable to your full dataset. Once we scale our image to full size, it takes almost 20 hours to train a single model, and we only have little chance to tune the hyper-parameters before the competition end. . Debug &amp; Checkpoint . There was a time we develop our model separately and we didn&#39;t sync our code for a while. We refactor our code during the time and it was a huge mistake. It turns out our pre-refactor code trains much better model and we introduce some unknown bug. It is almost impossible to find out as we change multiple things. It is so hard to debug a neural network and testing it thoroughly is important. Injecting a large amount of code may help you to run an experiment earlier, but you may pay much more time to debug it afterwards. . I think this is applicable even if you are working alone. . Keep your changes small. | Establish a baseline early, always do a regression test after a new feature introduced (especially after code refactoring) | Create checkpoint to rollback anytime, especially if you are not working on it every day. | . Implementation is the key of Kaggle competition (in real life too). It does not matter how great your model is, a tiny little bug could have damaged your model silently . Use auxiliary label . As mentioned earlier, this competition requires to predict the root, vowel and the consonant part. In the training data, they actually provide the grapheme too. Lots of people saying that if you train with the grapheme, it improves the model greatly and get the recall &gt;98% easily. . This is something we could not reproduce throughout the competition, we tried it in the very last minute but it does not seem to improve our model. It turns out lots of people are overfitting the data, as the testing dataset has much more unseen character. . But it is still a great remark that training with labels that is not your final desired output could still be very useful. . Weight loss . The distribution of the training dataset is very imbalance, but to get a good result, we need to predict every single class accurately (macro recall). To deal with this issue, we choose to use class weights, where a higher weight would be applied to rare samples. We don&#39;t have an ablation study for this, but it seems to help close the gap between accuracy &amp; recall and allows us to train the model slightly better. . Find a teammate! . Lastly, please go and find a teammate if you can. It is very common to start a Kaggle competition, but not so easy to finish them. I have stopped for a month during the competition due to my job. It is really hard to get back to the competition after you stopped for so long. Getting a teammate helps to motivate you and in the end, it is a great learning experience for both of us. . Pretrain Model . We also tried to use a pretrained model, as it allows shorter training and gives better performance by transfer learning (Using weights learn from a large dataset to as initial weight). It also gives our model a bit of improvement. . Finetune the model head, while keeping other layers freeze (except BatchNorm layer). | Unfreeze the model, train all the layers together. | . I also tried training the model directly with discriminating learning rate while not freezing any layer at all. It performs similarly to freezing fine-tuning , so I end up just start training the entire model from the beginning. . If the code works, don&#39;t touch it . This is probably not a good habit usually, but I suggest not to do it for a competition. We spent lots of time for debugging our code after code refactoring and end up just rolling back to an older commit and cherry-picks new features. In a competition, you don&#39;t have enough time to test everything. You do not need a nice abstract class for all your features, some refactoring to keep your function/class clean is probably needed, but do not overspend your time on it. It is even common to jump between frameworks (you may find other&#39;s Kernel useful), so it is not possible to structure your code perfectly. . If someone has create a working submission script, use it! | If someone has create a working pre-processing function, use it! | . Don&#39;t spend time on trying to optimize these code unless it is necessary, it is often not worth it in a competition context. You should focus on adding new features, trying out new model, testing with new augmentation technique instead. . Summary . This is a great learning experience and refreshes some of my outdated computer vision model knowledge. If you have never joined a competition, find a friend and get started. If you have just finished one, try writing it out and share your experience. üòâ .",
            "url": "https://mediumnok.ml/ml/kaggle/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html",
            "relUrl": "/ml/kaggle/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html",
            "date": " ‚Ä¢ Mar 21, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "The missing piece in Python tutorial - What is dispatch why you should care",
            "content": "In python, we often think of it as a dynamic language, and type is barely noticed in Python as you can change the type of a variable whenever you want. . Since Python 3.4(PEP443)[https://www.python.org/dev/peps/pep-0443/], generic function is added to Python. This add a new feature that I found much of the exsiting tutorial does not cover it. Such feature is common in other language and is very useful to keep your code concise and clean. . In python, you cannot overload a normal function twice for different behavior base on the arguments. For example: . def foo(number:int ): print(&#39;it is a integer&#39;) def foo(number: float): print(&#39;it is a float&#39;) . foo(1) . it is a float . The definition simply get replaced by the second definition. However, with singledispatch, you can define the function behavior base on the type of the argument. . from functools import singledispatch @singledispatch def foo(number ): print(f&#39;{type(number)}, {number}&#39;) . foo(1) . &lt;class &#39;int&#39;&gt;, 1 . We can now register the function for different argument type. . @foo.register(int) def _(data): print(&#39;It is a integer!&#39;) @foo.register(float) def _(data): print(&#39;It is a float!&#39;) @foo.register(dict) def _(data): print(&#39;It is a dict!&#39;) . foo(1.0) foo(1) foo({&#39;1&#39;:1}) . It is a float! It is a integer! It is a dict! . How is this possible? Basically there are multiple version of a generic function, singlepatch will pick the correct one base on the type of the first argument. . It will fallback to the most generic function if the type of argument is not registered. . foo([1,2,3]) . &lt;class &#39;list&#39;&gt;, [1, 2, 3] . I hope you can see how this is going to be useful. singledispatch limited the usage to the first argument of a function. But we can actually do more than that. . In next post I will cover the patch method from fastai will leverage singledispatch more to do multi-dispatch. In python, everything is just an object, even a function itself. So there is no reason why you can only dispatch to a function object. In fact, you could dispatch method to a class too. . Fastai @typedispatch . Single Dispatch is great, but what if we can do multi dispatch for more than 1 argument? . from fastcore.dispatch import typedispatch, TypeDispatch . Let us first try if this work as expected . @typedispatch def add(x:int, y:int): return x+y @typedispatch def add(x:int, y:str): return x + int(y) . print(add(1,2)) print(add(1,&#39;2&#39;)) print(add(&#39;a&#39;,&#39;a&#39;)) . 3 3 a . add(1,2) . 3 . add(1,&#39;2&#39;) . 3 . But what if we added something does not define? . add(&#39;2&#39;,1) . &#39;2&#39; . &#39;2&#39;? where does it come from? Let&#39;s have a look at the definition of typedispatch and understand how it works. . ??typedispatch class DispatchReg: &quot;A global registry for `TypeDispatch` objects keyed by function name&quot; def __init__(self): self.d = defaultdict(TypeDispatch) def __call__(self, f): nm = f&#39;{f.__qualname__}&#39; self.d[nm].add(f) return self.d[nm] . In fact, typedispatch is not even a function, it&#39;s an instance! In python, everything is an object. With the __call__ method, we can use an instance just liek a function. And the typedispatch is just an instance of DispatchReg . type(typedispatch) . fastcore.dispatch.DispatchReg . typedispatch store a dictionary inside, when you first register your function, it actually store inside a dict. As shown previously, you cannot define the same function twice. But you actually can, because function is nothing but just an object! Let me show you. . def foo(): return &#39;foo&#39; a = foo def foo(): return &#39;not foo&#39; b = foo . foo() . &#39;not foo&#39; . foo() is replaced by the latest definition indeed, but we store a copy of the original function as a variable. . a() . &#39;foo&#39; . b() . &#39;not foo&#39; . hex(id(a)), hex(id(b)) . (&#39;0x2b9d28bb5e8&#39;, &#39;0x2b9d2ebe048&#39;) . The two function is nothing other than two Python object. typedispatch make use of these, when you register a new function, you create an new object and stored inside typedispatch dictionary. It then checks your type annotation and find the corresponding type until it match the issubclass condition. . typedispatch.d . defaultdict(fastcore.dispatch.TypeDispatch, {&#39;cast&#39;: (object,object) -&gt; cast, &#39;add&#39;: (int,str) -&gt; add (int,int) -&gt; add}) . So back to our question, why does add(&#39;a&#39;,1) return &#39;a&#39;? The following explain the reasons. When you call your method, you are really calling the __call__ method inside TypeDispatch, and when the signature is not find, it will simply return the first argument. . def __call__(self, *args, **kwargs): ts = L(args).map(type)[:2] f = self[tuple(ts)] if not f: return args[0] if self.inst is not None: f = MethodType(f, self.inst) return f(*args, **kwargs) .",
            "url": "https://mediumnok.ml/fastai-x/2020/02/22/Python-Dynamic-Dispatch.html",
            "relUrl": "/fastai-x/2020/02/22/Python-Dynamic-Dispatch.html",
            "date": " ‚Ä¢ Feb 22, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc: true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 | The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 | First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 | I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 | Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 | Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![123](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://mediumnok.ml/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "data augmentation - Understand MixUp and Beta Distribution",
            "content": "GitHub: https://github.com/noklam/notadatascientist/tree/master/demo/mixup-beta . Understand Mixup Augmentation &amp; Beta Distribution . Implementation In the original article, the authors suggested three things: . Create two separate dataloaders and draw a batch from each at every iteration to mix them up | Draw a t value following a beta distribution with a parameter alpha (0.4 is suggested in their article) | Mix up the two batches with the same value t. | Use one-hot encoded targets | Source: https://forums.fast.ai/t/mixup-data-augmentation/22764 (Sylvain Gugger) . Beta Distribution . Beta distribution is control by two parameters, Œ± and Œ≤ with interval [0, 1], which make it useful for Mixup. Mixup is basically a superposition of two image with a parameter t. Instead of using a dog image, with Mixup, you may end up have a image which is 0.7 dog + 0.3 cat . To get some sense of what a beta distribution is, let plot beta distribution with different alpha and beta to see its effect . import math import torch import matplotlib.pyplot as plt from torch import tensor . # PyTorch has a log-gamma but not a gamma, so we&#39;ll create one Œì = lambda x: x.lgamma().exp() facts = [math.factorial(i) for i in range(7)] plt.plot(range(7), facts, &#39;ro&#39;) plt.plot(torch.linspace(0,6), Œì(torch.linspace(0,6)+1)) plt.legend([&#39;factorial&#39;,&#39;Œì&#39;]); . . When Œ± != Œ≤ . _,ax = plt.subplots(1,1, figsize=(5,4)) x = torch.linspace(0.01,0.99, 100000) a_ls = [5.0,1.0,0.4, 1.0] b_ls = [1.0,5.0,0.4, 1.0] for a, b in zip(a_ls, b_ls): a=tensor(a,dtype=torch.float) b=tensor(b,dtype=torch.float) # y = (x.pow(Œ±-1) * (1-x).pow(Œ±-1)) / (gamma_func(Œ± ** 2) / gamma_func(Œ±)) y = (x**(a-1) * (1-x)**(b-1)) / (Œì(a)*Œì(b) / Œì(a+b)) ax.plot(x,y) # ax.set_title(f&quot;Œ±={a.numpy()[0]:.1}&quot;) ax.set_title(&#39;Beta distribution when Œ± != Œ≤ &#39;) ax.legend([f&#39;Œ± = {float(a):.2}, Œ≤ = {float(b):.2}&#39; for a,b in zip(a_ls, b_ls)]) . C: ProgramData Anaconda3 envs fastai2 lib site-packages IPython core pylabtools.py:132: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data. fig.canvas.print_figure(bytes_io, **kw) . . A few observations from this graph. . Œ± and Œ≤ control the curve symmetrically, the blue line is symmetric with the orange line. | when Œ± and Œ≤ = 1, it reduce to uniform distribution | when Œ± = Œ≤, the distribution is a symmetric distribution | . When Œ± != Œ≤ . _,ax = plt.subplots(1,1, figsize=(5,4)) x = torch.linspace(0.01,0.99, 100000) a_ls = [0.1, 0.4, 0.6, 0.9] b_ls = [0.1, 0.4, 0.6, 0.9] for a, b in zip(a_ls, b_ls): a=tensor(a,dtype=torch.float) b=tensor(b,dtype=torch.float) # y = (x.pow(Œ±-1) * (1-x).pow(Œ±-1)) / (gamma_func(Œ± ** 2) / gamma_func(Œ±)) y = (x**(a-1) * (1-x)**(b-1)) / (Œì(a)*Œì(b) / Œì(a+b)) ax.plot(x,y) # ax.set_title(f&quot;Œ±={a.numpy()[0]:.1}&quot;) ax.set_title(&#39;Beta distribution when Œ± = Œ≤ &#39;) ax.legend([f&#39;Œ± = {float(a):.2}, Œ≤ = {float(b):.2}&#39; for a,b in zip(a_ls, b_ls)]) . C: ProgramData Anaconda3 envs fastai2 lib site-packages IPython core pylabtools.py:132: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data. fig.canvas.print_figure(bytes_io, **kw) . . As we remember, when Œ± = Œ≤ =1, it is an uniform distribution. When Œ± = Œ≤ , when Œ± is small, most density is concentrated around 0 and 1, and when Œ± increase, the distribution get more evenly distributed. . The default for Œ± suggested by the paper is 0.4 .",
            "url": "https://mediumnok.ml/ml/2020/02/09/MixUp-and-Beta-Distribution.html",
            "relUrl": "/ml/2020/02/09/MixUp-and-Beta-Distribution.html",
            "date": " ‚Ä¢ Feb 9, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Hydra - Config Composition for Machine Learning Project",
            "content": "GitHub: https://github.com/noklam/notadatascientist/tree/master/demo/hydra-example . Machine learning project involves large number of hyperparmeters. In many case you could have multiple config, e.g. differnet dataset, database connection, train/test mode. hydra provide a simple Command Line Interface that is useful for composing different experiment configs. In essence, it compose different files to a large config setting. It offers you the common Object Oriented Programming with YAML file. Allow you to have clear structure of configurations. . Assume you have a config.yaml like this, where run_mode and hyperparmeter are separate folder to hold different choice of parameters. You can set defaults for them with the following structure. . Folder Structure . config.yaml demo.py run_mode - train.yaml - test.yaml hyperparmeter - base.yaml . config.yaml . defaults: - run_mode: train - hyperparameter: base . The benefit of using such approach is that it makes comparsion of experiments much easier. Instead of going through the parameters list, you only focus on the argument(the difference). It helps organize machine learning results and ease a lot of pain in tracking the model performance. . import hydra from omegaconf import DictConfig @hydra.main(config_path=&quot;config.yaml&quot;) def my_app(cfg : DictConfig) -&gt; None: print(cfg.pretty()) if __name__ == &quot;__main__&quot;: my_app() . python demo.py . gamma: 0.01 learning_rate: 0.01 run_mode: train week: 8 . For example, with a simple example with 4 parameters only, you can simply run the experiment with default . Override default parameters . You can easily overrite the learning rate with an argument, it would be very clear that learning rate is the only changing parameter with this approach . python demo.py learning_rate=0.1 . gamma: 0.01 learning_rate: 0.1 run_mode: train week: 8 . In somecase, you may only need to test a model instead of changing it. . python demo.py learning_rate=0.1 run_mode=test . gamma: 0.01 learning_rate: 0.1 run_mode: test week: 8 . It also safeguard your experiment if you pass in some parameters that is not exist . !python demo.py typo=0.2 . Traceback (most recent call last): File &quot;demo.py&quot;, line 7, in &lt;module&gt; my_app() &quot;C: ProgramData Anaconda3 lib site-packages omegaconf dictconfig.py&quot;, line 41, in __setitem__ &quot;Accessing unknown key in a struct : {}&quot;.format(self.get_full_key(key)) KeyError: &#39;Accessing unknown key in a struct : typo&#39; . ‚ÄìMultirun, Combination of parameters . In case you want to gridsearch paramters, which is very common in machine learning, you can use an additional argument multirun to do that easily. . !python demo.py --multirun learning_rate=0.1,0.01,0.001 gamma=0.1,0.01 . [2020-02-08 19:28:46,095][HYDRA] Sweep output dir : multirun/2020-02-08/19-28-46 [2020-02-08 19:28:46,102][HYDRA] Launching 6 jobs locally [2020-02-08 19:28:46,103][HYDRA] #0 : learning_rate=0.1 gamma=0.1 gamma: 0.1 learning_rate: 0.1 run_mode: train week: 8 [2020-02-08 19:28:46,192][HYDRA] #1 : learning_rate=0.1 gamma=0.01 gamma: 0.01 learning_rate: 0.1 run_mode: train week: 8 ... SKIPPED .",
            "url": "https://mediumnok.ml/coding/ml/2020/02/08/Config-Composition-with-Hydra-for-Machine-Learning-Experiments.html",
            "relUrl": "/coding/ml/2020/02/08/Config-Composition-with-Hydra-for-Machine-Learning-Experiments.html",
            "date": " ‚Ä¢ Feb 8, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://mediumnok.ml/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "plyer - Desktop Notification in Python",
            "content": "from plyer import notification import random class DesktopNotification: @staticmethod def notify(title=&#39;Hey~&#39;, message=&#39;Done!&#39;, timeout=10): ls = [&#39;üëç&#39;,&#39;‚úî&#39;,&#39;‚úå&#39;,&#39;üëå&#39;,&#39;üëç&#39;,&#39;üòé&#39;] notification.notify( title = title , message = random.choice(ls) * 3 + &#39; &#39; + message, timeout = timeout # seconds ) if __name__ == &#39;__main__&#39;: DesktopNotification.notify() . You could add this simple code block to notify you when the program is done! A desktop notification will be prompt on the bottom right corner in Window. .",
            "url": "https://mediumnok.ml/coding/2019/10/19/Deskto-Notification.html",
            "relUrl": "/coding/2019/10/19/Deskto-Notification.html",
            "date": " ‚Ä¢ Oct 19, 2019"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it‚Äôs in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://mediumnok.ml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "fastai-x",
          "content": "fastai-related . 1st post for fastai-course v4 .",
          "url": "https://mediumnok.ml/fastai-x/",
          "relUrl": "/fastai-x/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://mediumnok.ml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}