{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial-yahoo",
   "metadata": {},
   "source": [
    "# Full Stack Deep Learning Notes - Lecture 03 - Recurrent Neural Network\n",
    "> Lecture & Lab notes - This lecture is about Recurrent Neural Network. Key concetps included input gate, forget gate, cell state, and output gate. It also explains how attention mechanism works for a encoder-decoder based architecture.\n",
    "\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: noklam\n",
    "- categories: [\"fsdl\"]\n",
    "- hide: false\n"
   ]
  },
  {
   "source": [
    "# LSTM\n",
    "Reference: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "The diagrams are from Chris Colah's blog.\n",
    "\n",
    "\n",
    "| RNN | LSTM |\n",
    "|---|---|\n",
    "| ![RNN](images/rnn.png) | ![LSTM](images/lstm.png) |\n",
    "\n",
    "\n",
    "\n",
    "![forget](images/lstm_forget.png)\n",
    "Forget Gate - Control the magnitude of cell state should be kept. Sigmoid range from (0 to 1). If 0, it means we should throw away the state cell, if 1 we keep everything.\n",
    "![input](images/lstm_input.png)\n",
    "* Input Gate - Control what relevant information can be added from the current step. It takes hidden step from last step and the current input into consideration.\n",
    "![output](images/lstm_output.png)\n",
    "* Output Gate - finalize the next hidden state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# # Google Neurl Machine Translation (GNMT)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It more or less follow the attention mechanism described here.\n",
    "\n",
    "https://blog.floydhub.com/attention-mechanism/#luong-att-step6\n",
    "\n",
    "![attention_gnmt](images/attention_gnmt.png)\n",
    "\n",
    "\t\n",
    "1.If you take the dot product of 1 encoder vector (at t_i) and decoder, you get a scalar. (Alignment Score) (1,h) * (h,1)  -> (1,1)\n",
    "2. If encoder have 5 time_step, repeat the above steps -> You get a vector with length of 5 (A vector of Alignment Scores) (5,h) *(h,1) -> (5,1)\n",
    "3. Take softmax of the alignments scores -> (attention weights which sum to 1) (5,1)\n",
    "4. Take dot product of encoders state with attention weights (h, 5) * (5, 1) -> (h, 1), where h stands for dimension of hidden state. The result is a \"Context Vector\"\n",
    "![context](images/context_vector.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python371jvsc74a57bd016f988c202c6d5b67fae213fcd58a128d4933d9f6b0a0be940c9d00563b3fdfe",
   "display_name": "Python 3.7.1 64-bit ('blog': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}