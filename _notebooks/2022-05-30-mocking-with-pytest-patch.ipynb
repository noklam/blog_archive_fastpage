{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Mocking\n",
    "> I have been working with on some unit tests recently with mocking. There are some traps that I falled into and I want to document it here.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: noklam\n",
    "- hide: false\n",
    "- categories: [\"python\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Mocking?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytest-mock\n",
    "\n",
    "One of the mainstream mocking library is the standard one from `unittest`, there are also pytest plugin `pytest-mock` which wraps on `unittest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
      "rootdir: C:\\Users\\lrcno\\AppData\\Local\\Temp\\tmpiih077gv\n",
      "plugins: anyio-3.5.0, cov-3.0.0, mock-1.13.0\n",
      "collected 1 item\n",
      "\n",
      "_ipytesttmp.py .                                                         [100%]\n",
      "\n",
      "============================== 1 passed in 0.06s ==============================\n"
     ]
    }
   ],
   "source": [
    "%%pytest\n",
    "\n",
    "def test_sum():\n",
    "    assert 1 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mocking is important for a few reasons.\n",
    "* You want to have fast unittest (within second)\n",
    "* You don't want to put loading or have any side-effect to your actual servers/database (e.g. mock writing to a database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Mock` and `MagicMock`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main mock object you can used with the standard `unittest` library from `unittest.mock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import Mock, MagicMock, patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock = Mock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `Mock` object, you can treat it like a magic object that have any attributes or methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Mock name='mock.super_method()' id='1587554283232'>,\n",
       " <Mock name='mock.attribute_that_does_not_exist_at_all' id='1587554282512'>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock.super_method(), mock.attribute_that_does_not_exist_at_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<Mock id='1587554282848'>\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MagicMock\n",
    "The \"magic\" comes from the magic methods of python object, for example, when you add two object together, it is calling the `__add__` magic method under the hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Mock' and 'Mock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20248/2007264031.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmock\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Mock' and 'Mock'"
     ]
    }
   ],
   "source": [
    "mock + mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_mock = MagicMock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MagicMock name='mock.__add__()' id='1587563722784'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magic_mock + magic_mock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `MagicMock`, you get these magic methods for free, this is why adding two mock will not throw an error but adding two `Mock` will result in a `TypeError`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say we want to mock the `pandas.read_csv` function, because we don't actually want it to read a data, but just return some mock data whenever it is called. It's easier to explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocking with real library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
      "rootdir: C:\\Users\\lrcno\\AppData\\Local\\Temp\\tmpka9zv6ev\n",
      "plugins: anyio-3.5.0, cov-3.0.0, mock-1.13.0\n",
      "collected 1 item\n",
      "\n",
      "_ipytesttmp.py .                                                         [100%]\n",
      "\n",
      "============================== 1 passed in 0.09s ==============================\n"
     ]
    }
   ],
   "source": [
    "%%pytest\n",
    "import pandas as pd\n",
    "\n",
    "def test_read_csv(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
    "    mocker.patch(\"pandas.read_csv\", return_value = \"fake_data\")\n",
    "    assert pd.read_csv(\"some_data\") == \"fake_data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, you should get a `Dataframe` object, but here we mock the return value to return a `str`, and you can see the test actually pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mocker.patch` with `create=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
      "rootdir: C:\\Users\\lrcno\\AppData\\Local\\Temp\\tmpzbddlxxg\n",
      "plugins: anyio-3.5.0, cov-3.0.0, mock-1.13.0\n",
      "collected 1 item\n",
      "\n",
      "_ipytesttmp.py F                                                         [100%]\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "________________________________ test_read_csv ________________________________\n",
      "\n",
      "mocker = <pytest_mock.plugin.MockFixture object at 0x00000171B28B1820>\n",
      "\n",
      "    def test_read_csv(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
      ">       mocker.patch(\"pandas.read_special_csv\", return_value = \"fake_data\", create=False)\n",
      "\n",
      "_ipytesttmp.py:4: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "..\\..\\..\\..\\miniconda3\\lib\\site-packages\\pytest_mock\\plugin.py:193: in __call__\n",
      "    return self._start_patch(self.mock_module.patch, *args, **kwargs)\n",
      "..\\..\\..\\..\\miniconda3\\lib\\site-packages\\pytest_mock\\plugin.py:157: in _start_patch\n",
      "    mocked = p.start()\n",
      "..\\..\\..\\..\\miniconda3\\lib\\unittest\\mock.py:1529: in start\n",
      "    result = self.__enter__()\n",
      "..\\..\\..\\..\\miniconda3\\lib\\unittest\\mock.py:1393: in __enter__\n",
      "    original, local = self.get_original()\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <unittest.mock._patch object at 0x00000171B28B10D0>\n",
      "\n",
      "    def get_original(self):\n",
      "        target = self.getter()\n",
      "        name = self.attribute\n",
      "    \n",
      "        original = DEFAULT\n",
      "        local = False\n",
      "    \n",
      "        try:\n",
      "            original = target.__dict__[name]\n",
      "        except (AttributeError, KeyError):\n",
      "            original = getattr(target, name, DEFAULT)\n",
      "        else:\n",
      "            local = True\n",
      "    \n",
      "        if name in _builtins and isinstance(target, ModuleType):\n",
      "            self.create = True\n",
      "    \n",
      "        if not self.create and original is DEFAULT:\n",
      ">           raise AttributeError(\n",
      "                \"%s does not have the attribute %r\" % (target, name)\n",
      "            )\n",
      "E           AttributeError: <module 'pandas' from 'c:\\\\users\\\\lrcno\\\\miniconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'> does not have the attribute 'read_special_csv'\n",
      "\n",
      "..\\..\\..\\..\\miniconda3\\lib\\unittest\\mock.py:1366: AttributeError\n",
      "=========================== short test summary info ===========================\n",
      "FAILED _ipytesttmp.py::test_read_csv - AttributeError: <module 'pandas' from ...\n",
      "============================== 1 failed in 0.43s ==============================\n"
     ]
    }
   ],
   "source": [
    "%%pytest\n",
    "import pandas as pd\n",
    "\n",
    "def test_read_csv(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
    "    mocker.patch(\"pandas.read_special_csv\", return_value = \"fake_data\", create=False)\n",
    "    assert pd.read_special_csv(\"some_data\") == \"fake_data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fail the test because `pandas.read_special_csv` does not exist. However, with `create=True` you can make the test pass again. Normally you won't want to do this, but it is an option that available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0\n",
      "rootdir: C:\\Users\\lrcno\\AppData\\Local\\Temp\\tmphqbckliw\n",
      "plugins: anyio-3.5.0, cov-3.0.0, mock-1.13.0\n",
      "collected 1 item\n",
      "\n",
      "_ipytesttmp.py .                                                         [100%]\n",
      "\n",
      "============================== 1 passed in 0.10s ==============================\n"
     ]
    }
   ],
   "source": [
    "%%pytest\n",
    "import pandas as pd\n",
    "\n",
    "def test_read_csv(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
    "    mocker.patch(\"pandas.read_special_csv\", return_value = \"fake_data\", create=True)\n",
    "    assert pd.read_special_csv(\"some_data\") == \"fake_data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often, you would want your mock resemble your real object, which means it has the same attributes and method, but it should fails when the method being called isn't valid.\n",
    "You may specify the `return_value` with the mock type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.8.5, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- c:\\users\\lrcno\\miniconda3\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\lrcno\\AppData\\Local\\Temp\\tmpyfiqtkoy\n",
      "plugins: anyio-3.5.0, cov-3.0.0, mock-1.13.0\n",
      "collecting ... collected 2 items\n",
      "\n",
      "_ipytesttmp.py::test_read_csv_valid_method PASSED                        [ 50%]\n",
      "_ipytesttmp.py::test_read_csv_invalid_method PASSED                      [100%]\n",
      "\n",
      "============================== 2 passed in 0.16s ==============================\n"
     ]
    }
   ],
   "source": [
    "%%pytest -vvv\n",
    "import pandas as pd\n",
    "from unittest.mock import Mock\n",
    "import pytest\n",
    "\n",
    "def test_read_csv_valid_method(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
    "    mocker.patch(\"pandas.read_csv\", return_value = Mock(pd.DataFrame))\n",
    "    df =  pd.read_csv(\"some_data\")\n",
    "    df.mean()  # A DataFrame method\n",
    "\n",
    "def test_read_csv_invalid_method(mocker):  # mocker is a special pytest fixture, so even though we haven't define it here but pytest understands it.\n",
    "    mocker.patch(\"pandas.read_csv\", return_value = Mock(pd.DataFrame))\n",
    "    df =  pd.read_csv(\"some_data\")\n",
    "    with pytest.raises(Exception):\n",
    "        df.not_a_dataframe_method()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
